{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region  = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                    role=role,\n",
    "                                    instance_type='ml.m5.large',\n",
    "                                    instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# input data s3://sklearn-script/census/census-income.csv\n",
    "\n",
    "input_data_train = 's3://sklearn-script/taxi/train.csv'\n",
    "input_data_test = 's3://sklearn-script/taxi/test.csv'\n",
    "\n",
    "output_destination = 's3://sklearn-script/taxi/'\n",
    "\n",
    "df = pd.read_csv(input_data_train)\n",
    "#df.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21+00:00</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16+00:00</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00+00:00</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42+00:00</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00+00:00</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount            pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0          4.5  2009-06-15 17:26:21+00:00        -73.844311        40.721319   \n",
       "1         16.9  2010-01-05 16:52:16+00:00        -74.016048        40.711303   \n",
       "2          5.7  2011-08-18 00:35:00+00:00        -73.982738        40.761270   \n",
       "3          7.7  2012-04-21 04:30:42+00:00        -73.987130        40.733143   \n",
       "4          5.3  2010-03-09 07:51:00+00:00        -73.968095        40.768008   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.841610         40.712278                1  \n",
       "1         -73.979268         40.782004                1  \n",
       "2         -73.991242         40.750562                2  \n",
       "3         -73.991567         40.758092                1  \n",
       "4         -73.956655         40.783762                1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelBinarizer,KBinsDiscretizer,StandardScaler  \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "\n",
    "# Radius of the earth in kilometers\n",
    "R = 6378\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "    \n",
    "    source: https://stackoverflow.com/a/29546836\n",
    "\n",
    "    \"\"\"\n",
    "    # Convert latitude and longitude to radians\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Find the differences\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    # Apply the formula \n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    # Calculate the angle (in radians)\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    # Convert to kilometers\n",
    "    km = R * c\n",
    "    \n",
    "    return km\n",
    "\n",
    "def data_transformation(df,train_flag = True):\n",
    "\n",
    "    ohe_columns = ['hour','weekday','day','month','year']\n",
    "    traget_col = ['fare_amount']\n",
    "    nom_columns = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','distance']\n",
    "    \n",
    "    # drop na values\n",
    "    df = df.dropna()\n",
    "    if train_flag:\n",
    "        # remove outliers\n",
    "        df = df[df['fare_amount'].between(left=2.5,right=100)]\n",
    "       \n",
    "    # removing outliers in passenger count \n",
    "    df = df[(df['passenger_count'] <= 6) & (df['passenger_count'] >=1)]\n",
    "\n",
    "    # removing outliners in lat, lag features\n",
    "    df = df.loc[df['pickup_latitude'].between(40, 42)]\n",
    "    df = df.loc[df['pickup_longitude'].between(-75, -72)]\n",
    "\n",
    "    # dropoff\n",
    "    df = df.loc[df['dropoff_latitude'].between(40, 42)]\n",
    "    df = df.loc[df['dropoff_longitude'].between(-75, -72)]\n",
    "\n",
    "    ## adding new features\n",
    "    df['hour']    = df['pickup_datetime'].dt.hour\n",
    "    df['weekday'] = df['pickup_datetime'].dt.dayofweek\n",
    "    df['day']     = df['pickup_datetime'].dt.day\n",
    "    df['month']   = df['pickup_datetime'].dt.month\n",
    "    df['year']    = df['pickup_datetime'].dt.year\n",
    "\n",
    "    # removing pickup_datetime feature\n",
    "    df.drop('pickup_datetime',axis=1,inplace=True)\n",
    "\n",
    "    ## adding new feature haversine_np distance\n",
    "    df['distance'] = haversine_np(df['pickup_longitude'],df['pickup_latitude'],df['dropoff_longitude'],df['dropoff_latitude'])\n",
    "    \n",
    "    # transformation\n",
    "    #One hot encoding the cataogrical features.\n",
    "    ohe = OneHotEncoder(categories='auto')\n",
    "    ohe_mat = ohe.fit_transform(df[ohe_columns])\n",
    "\n",
    "    # converting nom features to csr matrix format\n",
    "    df_nom = sparse.csr_matrix(df[nom_columns].values)\n",
    "\n",
    "    # merging\n",
    "    df_csr = sparse.hstack((df_nom,ohe_mat))\n",
    "    \n",
    "    if train_flag:\n",
    "        # target variable\n",
    "        y = df[traget_col].values\n",
    "        \n",
    "        return df_csr,y\n",
    "    \n",
    "    return df_csr\n",
    "\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "\n",
    "    input_data_path_train = os.path.join('/opt/ml/processing/input_train', 'train.csv')\n",
    "    input_data_path_test = os.path.join('/opt/ml/processing/input_test', 'test.csv')\n",
    "    \n",
    "    train = pd.read_csv(input_data_path_train,parse_dates=['pickup_datetime'])\n",
    "    test = pd.read_csv(input_data_path_test,parse_dates=['pickup_datetime'])\n",
    "    \n",
    "    train_features,y_train = data_transformation(train,train_flag=True)\n",
    "    test_features = data_transformation(test,train_flag=False)\n",
    "    \n",
    "    print('Train data shape after preprocessing: {}'.format(train_features.shape))\n",
    "    print('Test data shape after preprocessing: {}'.format(test_features.shape))\n",
    "    \n",
    "    train_features_output_path = os.path.join('/opt/ml/processing/train', 'train_features')\n",
    "    train_labels_output_path = os.path.join('/opt/ml/processing/train', 'train_labels')\n",
    "    \n",
    "    test_features_output_path = os.path.join('/opt/ml/processing/test', 'test_features')\n",
    "    \n",
    "    \n",
    "    print('Saving training features to {}'.format(train_features_output_path))\n",
    "    sparse.save_npz(train_features_output_path,train_features,)\n",
    "    \n",
    "    print('Saving test features to {}'.format(test_features_output_path))\n",
    "    sparse.save_npz(test_features_output_path,test_features)\n",
    "    \n",
    "    print('Saving training labels to {}'.format(train_labels_output_path))\n",
    "    np.save(train_labels_output_path,y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  sagemaker-scikit-learn-2020-01-04-11-58-46-501\n",
      "Inputs:  [{'InputName': 'input-1', 'S3Input': {'S3Uri': 's3://sklearn-script/taxi/train.csv', 'LocalPath': '/opt/ml/processing/input_train', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'S3Input': {'S3Uri': 's3://sklearn-script/taxi/test.csv', 'LocalPath': '/opt/ml/processing/input_test', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-166087373671/sagemaker-scikit-learn-2020-01-04-11-58-46-501/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'train_data', 'S3Output': {'S3Uri': 's3://sklearn-script/taxi/', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'S3Output': {'S3Uri': 's3://sklearn-script/taxi/', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..................\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mTrain data shape after preprocessing: (9747, 86)\u001b[0m\n",
      "\u001b[34mTest data shape after preprocessing: (9914, 86)\u001b[0m\n",
      "\u001b[34mSaving training features to /opt/ml/processing/train/train_features.csv\u001b[0m\n",
      "\u001b[34mSaving test features to /opt/ml/processing/test/test_features.csv\u001b[0m\n",
      "\u001b[34mSaving training labels to /opt/ml/processing/train/train_labels.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor.run(code='preprocessing.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=input_data_train,\n",
    "                        destination='/opt/ml/processing/input_train'),\n",
    "                              ProcessingInput(\n",
    "                                  source=input_data_test,\n",
    "                                  destination='/opt/ml/processing/input_test')],\n",
    "                      outputs=[ProcessingOutput(output_name='train_data',\n",
    "                                                destination = output_destination,\n",
    "                                                source='/opt/ml/processing/train'),\n",
    "                               ProcessingOutput(output_name='test_data',\n",
    "                                                destination = output_destination,\n",
    "                                                source='/opt/ml/processing/test')]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_job_description = sklearn_processor.jobs[-1].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingInputs': [{'InputName': 'input-1',\n",
       "   'S3Input': {'S3Uri': 's3://sklearn-script/taxi/train.csv',\n",
       "    'LocalPath': '/opt/ml/processing/input_train',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'input-2',\n",
       "   'S3Input': {'S3Uri': 's3://sklearn-script/taxi/test.csv',\n",
       "    'LocalPath': '/opt/ml/processing/input_test',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}},\n",
       "  {'InputName': 'code',\n",
       "   'S3Input': {'S3Uri': 's3://sagemaker-ap-south-1-166087373671/sagemaker-scikit-learn-2020-01-04-11-58-46-501/input/code/preprocessing.py',\n",
       "    'LocalPath': '/opt/ml/processing/input/code',\n",
       "    'S3DataType': 'S3Prefix',\n",
       "    'S3InputMode': 'File',\n",
       "    'S3DataDistributionType': 'FullyReplicated',\n",
       "    'S3CompressionType': 'None'}}],\n",
       " 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train_data',\n",
       "    'S3Output': {'S3Uri': 's3://sklearn-script/taxi/',\n",
       "     'LocalPath': '/opt/ml/processing/train',\n",
       "     'S3UploadMode': 'EndOfJob'}},\n",
       "   {'OutputName': 'test_data',\n",
       "    'S3Output': {'S3Uri': 's3://sklearn-script/taxi/',\n",
       "     'LocalPath': '/opt/ml/processing/test',\n",
       "     'S3UploadMode': 'EndOfJob'}}]},\n",
       " 'ProcessingJobName': 'sagemaker-scikit-learn-2020-01-04-11-58-46-501',\n",
       " 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "   'InstanceType': 'ml.m5.large',\n",
       "   'VolumeSizeInGB': 30}},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       " 'AppSpecification': {'ImageUri': '720646828776.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-scikit-learn:0.20.0-cpu-py3',\n",
       "  'ContainerEntrypoint': ['python3',\n",
       "   '/opt/ml/processing/input/code/preprocessing.py']},\n",
       " 'RoleArn': 'arn:aws:iam::166087373671:role/service-role/AmazonSageMaker-ExecutionRole-20191212T101145',\n",
       " 'ProcessingJobArn': 'arn:aws:sagemaker:ap-south-1:166087373671:processing-job/sagemaker-scikit-learn-2020-01-04-11-58-46-501',\n",
       " 'ProcessingJobStatus': 'Completed',\n",
       " 'ProcessingEndTime': datetime.datetime(2020, 1, 4, 12, 1, 45, tzinfo=tzlocal()),\n",
       " 'ProcessingStartTime': datetime.datetime(2020, 1, 4, 11, 59, 55, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 1, 4, 12, 1, 45, 365000, tzinfo=tzlocal()),\n",
       " 'CreationTime': datetime.datetime(2020, 1, 4, 11, 58, 46, 643000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'df2d0d7a-0cf5-49e4-8734-39b9934d8119',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'df2d0d7a-0cf5-49e4-8734-39b9934d8119',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1967',\n",
       "   'date': 'Sat, 04 Jan 2020 12:08:23 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_config = preprocessing_job_description['ProcessingOutputConfig']\n",
    "#output_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nfor output in output_config['Outputs']:\\n    if output['OutputName'] == 'train_data':\\n        preprocessed_training_data = output['S3Output']['S3Uri']\\n    if output['OutputName'] == 'test_data':\\n        preprocessed_test_data = output['S3Output']['S3Uri']\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "for output in output_config['Outputs']:\n",
    "    if output['OutputName'] == 'train_data':\n",
    "        preprocessed_training_data = output['S3Output']['S3Uri']\n",
    "    if output['OutputName'] == 'test_data':\n",
    "        preprocessed_test_data = output['S3Output']['S3Uri']\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using the pre-processed data# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn = SKLearn(\n",
    "    entry_point='train.py',\n",
    "    train_instance_type=\"ml.m5.large\",\n",
    "    role=role)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_training_data = 's3://sklearn-script/taxi/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import os \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import sparse\n",
    "import boto3\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    training_data_directory = '/opt/ml/input/data/train'\n",
    "    \n",
    "    train_features_data = os.path.join(training_data_directory, 'train_features.csv.npz')\n",
    "    \n",
    "    train_labels_data = os.path.join(training_data_directory, 'train_labels.csv.npy')\n",
    "    \n",
    "    s3 = boto3.client('s3')\n",
    "    \n",
    "    print(f'training data directory :{training_data_directory}')\n",
    "    print(f'training features path :{train_features_data}')\n",
    "    print(f'training labels path :{train_labels_data}')\n",
    "    \n",
    "    print('Reading input data')\n",
    "    \n",
    "    \n",
    "    X_train = sparse.load_npz(train_features_data)\n",
    "    y_train = np.load(train_labels_data)\n",
    "    \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    print('Training LR model')\n",
    "    model_output_directory = os.path.join('/opt/ml/model', \"model.joblib\")\n",
    "    \n",
    "    print('Saving model to {}'.format(model_output_directory))\n",
    "    joblib.dump(model, model_output_directory)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-04 16:16:35 Starting - Starting the training job...\n",
      "2020-01-04 16:16:38 Starting - Launching requested ML instances......\n",
      "2020-01-04 16:18:01 Starting - Preparing the instances for training...\n",
      "2020-01-04 16:18:33 Downloading - Downloading input data...\n",
      "2020-01-04 16:19:06 Training - Downloading the training image..\u001b[34m2020-01-04 16:19:19,791 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:19,794 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:19,803 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:20,026 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:20,026 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:20,026 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:20,026 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=4889 sha256=507cecd3f58ec7cc3fc709559b50b64d5b64ac9520583357e8646e0545e77fbe\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qhlsvcre/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:21,207 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:21,217 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-01-04-16-16-35-473\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-166087373671/sagemaker-scikit-learn-2020-01-04-16-16-35-473/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-166087373671/sagemaker-scikit-learn-2020-01-04-16-16-35-473/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-01-04-16-16-35-473\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-166087373671/sagemaker-scikit-learn-2020-01-04-16-16-35-473/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34mtraining data directory :/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mtraining features path :/opt/ml/input/data/train/train_features.csv.npz\u001b[0m\n",
      "\u001b[34mtraining labels path :/opt/ml/input/data/train/train_labels.csv.npy\u001b[0m\n",
      "\u001b[34mReading input data\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:481: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  self.coef_ = np.vstack(out[0] for out in outs)\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py:482: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  self._residues = np.vstack(out[3] for out in outs)\u001b[0m\n",
      "\u001b[34mTraining LR model\u001b[0m\n",
      "\u001b[34mSaving model to /opt/ml/model/model.joblib\u001b[0m\n",
      "\u001b[34m2020-01-04 16:19:22,218 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-04 16:19:31 Uploading - Uploading generated training model\n",
      "2020-01-04 16:19:31 Completed - Training job completed\n",
      "Training seconds: 58\n",
      "Billable seconds: 58\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sklearn.fit({'train': preprocessed_training_data})\n",
    "\n",
    "training_job_description = sklearn.jobs[-1].describe()\n",
    "\n",
    "model_data_s3_uri = '{}{}/{}'.format(\n",
    "    training_job_description['OutputDataConfig']['S3OutputPath'],\n",
    "    training_job_description['TrainingJobName'],\n",
    "    'output/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "obj = s3.get_object(Bucket='sklearn-script', Key='sklearn-script/taxi/train_features.csv.npz')\n",
    "\n",
    "X_train = sparse.load_npz(BytesIO(obj['Body'].read()))\n",
    "\n",
    "obj = s3.get_object(Bucket='sklearn-script', Key='taxi/train_labels.csv.npy')\n",
    "\n",
    "y_train = np.load(BytesIO(obj['Body'].read()))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.63810099],\n",
       "       [19.84125233],\n",
       "       [ 5.41045209],\n",
       "       ...,\n",
       "       [12.99612292],\n",
       "       [ 8.42002382],\n",
       "       [13.24840725]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from s3fs.core import S3FileSystem\n",
    "s3 = S3FileSystem()\n",
    "\n",
    "key = 'taxi/train_features.csv.npz'\n",
    "bucket = 'sklearn-script'\n",
    "\n",
    "df = sparse.load_npz(s3.open('{}/{}'.format(bucket, key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9747, 86)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nMissing required parameter in input: \"Bucket\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-225f9f117dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ms3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m's3://sklearn-script/taxi/train_features.csv.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    632\u001b[0m         }\n\u001b[1;32m    633\u001b[0m         request_dict = self._convert_to_request_dict(\n\u001b[0;32m--> 634\u001b[0;31m             api_params, operation_model, context=request_context)\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mservice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[1;32m    680\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m    681\u001b[0m         request_dict = self._serializer.serialize_to_request(\n\u001b[0;32m--> 682\u001b[0;31m             api_params, operation_model)\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host_prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                                     operation_model.input_shape)\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[1;32m    299\u001b[0m                                                      operation_model)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nMissing required parameter in input: \"Bucket\""
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "obj = s3.get_object(Key='s3://sklearn-script/taxi/train_features.csv.npz')\n",
    "\n",
    "X_train = sparse.load_npz(BytesIO(obj['Body'].read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
