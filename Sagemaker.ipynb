{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading new-york-city-taxi-fare-prediction.zip to /home/ec2-user/SageMaker\n",
      "100%|█████████████████████████████████████▊| 1.55G/1.56G [02:09<00:00, 15.8MB/s]\n",
      "100%|██████████████████████████████████████| 1.56G/1.56G [02:09<00:00, 12.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_USERNAME'] = \"veerendar2888\" # username from the json file\n",
    "os.environ['KAGGLE_KEY'] = \"600e923d8c4f7b3a7241285ae4ed011f\" # key from the json file\n",
    "!kaggle competitions download -c new-york-city-taxi-fare-prediction # api copied from kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  new-york-city-taxi-fare-prediction.zip\r\n",
      "  inflating: GCP-Coupons-Instructions.rtf  \r\n",
      "  inflating: sample_submission.csv   \r\n",
      "  inflating: test.csv                \r\n"
     ]
    }
   ],
   "source": [
    "!unzip -o new-york-city-taxi-fare-prediction.zip -x train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# S3 prefix\n",
    "prefix = 'kaggle-cat'\n",
    "bucket = 'sklearn-script'\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Get a SageMaker-compatible role used by this Notebook Instance.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_file(\n",
    "    'train.csv', 'sklearn-script', 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "prefix =\n",
    "train_input = sagemaker_session.upload_data('test.csv',\n",
    "                                            bucket=bucket,\n",
    "                                            key_prefix =\"{}/{}\".format(prefix,WORK_DIRECTORY) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = 's3://{}/{}/{}/train.csv'.format(bucket,prefix,WORK_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(input_data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.t2.medium',\n",
    "                                     instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefilw preprocessing.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from haversine import haversine, Unit # mesuring distance (lat,lon)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix,hstack\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore',category=DataConversionWarning)\n",
    "\n",
    "\n",
    "def print_shape(df):\n",
    "    \n",
    "    print('Shape of train_x'.format(df.shape))\n",
    "    \n",
    "class OrdAttTransform(BaseEstimator,MetaEstimatorMixin):\n",
    "    def __init__(self,ord_attr):\n",
    "        self.ord_attr = ord_attr\n",
    "        ord_dict = {'Freezing':1,'Cold':2,'Warm':3,'Hot':4,\n",
    "                  'Boiling Hot':5,'Lava Hot':6,'Novice':1,\n",
    "                  'Contributor':2,'Expert':3,'Master':4,'Grandmaster':5}\n",
    "    def fit(self,X):\n",
    "        return self\n",
    "    def orde_scal(num_ordnl):\n",
    "        seq = np.linspace(0,1,num_ordnl)\n",
    "        return seq\n",
    "    def transform(self,X):\n",
    "    \n",
    "        for attr in ord_attr:\n",
    "\n",
    "            if attr in ('ord_1','ord_2'):\n",
    "            X[attr] = X[attr].map(ord_dict)\n",
    "\n",
    "            atlist = X[attr].unique().tolist()\n",
    "            atlist.sort()\n",
    "            arlist_len = len(atlist)\n",
    "      \n",
    "            attrmap = dict(zip(atlist, np.linspace(0,1,arlist_len)))\n",
    "            X[attr] = X[attr].map(attrmap)\n",
    "            return X\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Hyperparameters are described here. In this simple example we are just including one hyperparameter.\n",
    "    \n",
    "    parser.add_argument('--train-test-split-ration',type=float,\n",
    "                       default=0.3)\n",
    "    args,_ = parser.parse_known_args()\n",
    "    \n",
    "    print('Received arguments  {}',format(args))\n",
    "    \n",
    "    input_data_path_train = os.path.join('/opt/ml/processing/input',\n",
    "                                  'train.csv')\n",
    "    \n",
    "    input_data_path_test = os.path.join('/opt/ml/processing/input',\n",
    "                                  'test.csv')\n",
    "    \n",
    "    print('Reading input data form {}',format(input_data_path_train))\n",
    "    \n",
    "    ## data processing\n",
    "    ## load data\n",
    "    train = pd.read_csv(input_data_path_train)\n",
    "    test = pd.read_csv(input_data_path_test)\n",
    "    \n",
    "    # getting train test data id's\n",
    "    train_id = train['id']\n",
    "    test_id = test['id']\n",
    "    target = train['target']\n",
    "    \n",
    "    # merging train test data sets into one data frame for feature engineering \n",
    "    df = pd.concat([train.drop(labels=['id','target'],axis=1), test.drop(labels='id',axis=1)])\n",
    "    \n",
    "    # features\n",
    "    bin_attr = ['bin_3','bin_4']\n",
    "\n",
    "    ord_dict = {'Freezing':1,'Cold':2,'Warm':3,'Hot':4,\n",
    "                  'Boiling Hot':5,'Lava Hot':6,'Novice':1,\n",
    "                  'Contributor':2,'Expert':3,'Master':4,'Grandmaster':5}\n",
    "\n",
    "    ord_attr = ['ord_0','ord_1', 'ord_2', 'ord_3', 'ord_4', 'ord_5']\n",
    "\n",
    "    nom_attr = ['nom_0','nom_1','nom_2','nom_3','nom_4','nom_5','nom_6','nom_7','nom_8','nom_9','day','month']\n",
    "    \n",
    "    \n",
    "    class BinAttrTransform(BaseEstimator,MetaEstimatorMixin):\n",
    "        def __init__(self,bin_attr):\n",
    "            self.bin_attr = bin_attr\n",
    "        def fit(self,X,y=None):\n",
    "            return self\n",
    "        def transform(self,X):\n",
    "            bin_map = {'T':1,'F':0,'Y':1,'N':0}\n",
    "            for att in bin_attr:\n",
    "                X[att] = X[att].map(bin_map)\n",
    "            return X\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
